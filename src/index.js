import 'dotenv/config';
import { crawlAll, fetchAllJobUrls } from './crawlers/zighang-full.js';
import { sendKakaoMessage } from './kakao.js';

// Supabase ì„¤ì • (service_role key ì‚¬ìš© - RLS ìš°íšŒ)
const SUPABASE_URL = process.env.SUPABASE_URL || 'https://uphoiwlvglkogkcnrjkl.supabase.co';
const SUPABASE_SERVICE_KEY = process.env.SUPABASE_SERVICE_KEY;

if (!SUPABASE_SERVICE_KEY) {
  console.error('âŒ SUPABASE_SERVICE_KEY í™˜ê²½ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.');
  console.error('   Supabase Dashboard â†’ Settings â†’ API â†’ service_role key');
  process.exit(1);
}

/**
 * Supabase REST APIë¡œ upsert
 */
async function supabaseUpsert(table, rows) {
  const response = await fetch(`${SUPABASE_URL}/rest/v1/${table}`, {
    method: 'POST',
    headers: {
      'apikey': SUPABASE_SERVICE_KEY,
      'Authorization': `Bearer ${SUPABASE_SERVICE_KEY}`,
      'Content-Type': 'application/json',
      'Prefer': 'resolution=merge-duplicates',
    },
    body: JSON.stringify(rows),
  });

  if (!response.ok) {
    const error = await response.text();
    throw new Error(`Supabase upsert ì‹¤íŒ¨ (${table}): ${response.status} ${error}`);
  }

  return response;
}

/**
 * Supabaseì—ì„œ ë§ˆì§€ë§‰ í¬ë¡¤ë§ ì‹œê° ê°€ì ¸ì˜¤ê¸°
 */
async function getLastCrawledAt() {
  try {
    const response = await fetch(
      `${SUPABASE_URL}/rest/v1/crawl_metadata?id=eq.default&select=last_crawled_at`,
      {
        headers: {
          'apikey': SUPABASE_SERVICE_KEY,
          'Authorization': `Bearer ${SUPABASE_SERVICE_KEY}`,
        },
      }
    );

    const data = await response.json();
    return data[0]?.last_crawled_at || null;
  } catch {
    return null;
  }
}

/**
 * í¬ë¡¤ë§ ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
 */
async function updateCrawlMetadata(stats) {
  await supabaseUpsert('crawl_metadata', [{
    id: 'default',
    last_crawled_at: new Date().toISOString(),
    last_sitemap_check: new Date().toISOString(),
    total_jobs: stats.total,
    active_jobs: stats.success,
    updated_at: new Date().toISOString(),
  }]);
}

/**
 * ë°°ì¹˜ ì €ì¥ ì½œë°±: Supabase jobs í…Œì´ë¸”ì— upsert
 */
async function saveBatch(batch) {
  // ì‚­ì œëœ ê³µê³ ì™€ ì •ìƒ ê³µê³  ë¶„ë¦¬
  const activeJobs = batch.filter(j => j.is_active !== false && !j._deleted);
  const deletedIds = batch.filter(j => j.is_active === false || j._deleted).map(j => j.id);

  // ì •ìƒ ê³µê³  upsert
  if (activeJobs.length > 0) {
    await supabaseUpsert('jobs', activeJobs);
  }

  // ì‚­ì œëœ ê³µê³  ë¹„í™œì„±í™”
  for (const id of deletedIds) {
    await fetch(`${SUPABASE_URL}/rest/v1/jobs?id=eq.${id}`, {
      method: 'PATCH',
      headers: {
        'apikey': SUPABASE_SERVICE_KEY,
        'Authorization': `Bearer ${SUPABASE_SERVICE_KEY}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({ is_active: false }),
    });
  }

  console.log(`  ğŸ’¾ ì €ì¥: ${activeJobs.length}ê±´ upsert, ${deletedIds.length}ê±´ ë¹„í™œì„±í™”`);
}

/**
 * ìƒˆ ê³µê³  ì¹´ì¹´ì˜¤í†¡ ì•Œë¦¼ (ì„ íƒì )
 */
async function notifyNewJobs(newJobCount) {
  if (!process.env.KAKAO_ACCESS_TOKEN) return;
  if (newJobCount === 0) return;

  // ìµœê·¼ ì €ì¥ëœ ê³µê³  ì¤‘ ìƒìœ„ 5ê°œ ê°€ì ¸ì˜¤ê¸°
  try {
    const response = await fetch(
      `${SUPABASE_URL}/rest/v1/jobs?is_active=eq.true&order=crawled_at.desc&limit=5`,
      {
        headers: {
          'apikey': SUPABASE_SERVICE_KEY,
          'Authorization': `Bearer ${SUPABASE_SERVICE_KEY}`,
        },
      }
    );
    const recentJobs = await response.json();

    if (recentJobs.length > 0) {
      const formatted = recentJobs.map(j => ({
        company: j.company,
        title: j.title,
        link: `https://zighang.com/recruitment/${j.id}`,
        source: 'zighang',
      }));
      await sendKakaoMessage(formatted);
    }
  } catch (error) {
    console.error('ì¹´ì¹´ì˜¤ ì•Œë¦¼ ì˜¤ë¥˜:', error.message);
  }
}

/**
 * ë©”ì¸ ì‹¤í–‰
 */
async function main() {
  const isFullCrawl = process.argv.includes('--full');

  console.log('ğŸ• ì·¨ì—…í•˜ê°œ - ì±„ìš©ê³µê³  ìˆ˜ì§‘ê¸°');
  console.log(`ì‹œê°„: ${new Date().toLocaleString('ko-KR')}`);
  console.log(`ëª¨ë“œ: ${isFullCrawl ? 'ì „ì²´ ìˆ˜ì§‘' : 'ì¦ë¶„ ìˆ˜ì§‘'}\n`);

  // ì¦ë¶„ í¬ë¡¤ë§: ë§ˆì§€ë§‰ ìˆ˜ì§‘ì¼ ì´í›„ë§Œ
  let sinceDate = null;
  if (!isFullCrawl) {
    sinceDate = await getLastCrawledAt();
    if (sinceDate) {
      console.log(`ğŸ“… ë§ˆì§€ë§‰ ìˆ˜ì§‘: ${sinceDate}`);
    } else {
      console.log('ğŸ“… ì´ì „ ìˆ˜ì§‘ ê¸°ë¡ ì—†ìŒ â†’ ì „ì²´ ìˆ˜ì§‘ ëª¨ë“œë¡œ ì „í™˜');
    }
  }

  // í¬ë¡¤ë§ ì‹¤í–‰
  const result = await crawlAll({
    sinceDate,
    onBatch: saveBatch,
    onProgress: ({ current, total, success, failed }) => {
      // GitHub Actions ë¡œê·¸ìš©
    },
  });

  // ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
  await updateCrawlMetadata(result);

  // ì¹´ì¹´ì˜¤ ì•Œë¦¼
  await notifyNewJobs(result.success);

  console.log(`\nğŸ‰ ì™„ë£Œ! ì´ ${result.success}ê±´ ì €ì¥, ${result.failed}ê±´ ì‹¤íŒ¨, ${result.deleted}ê±´ ì‚­ì œ`);
}

main().catch(error => {
  console.error('âŒ ì¹˜ëª…ì  ì˜¤ë¥˜:', error);
  process.exit(1);
});
