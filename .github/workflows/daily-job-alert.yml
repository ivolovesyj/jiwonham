name: Daily Job Crawler

on:
  schedule:
    # ë§¤ì¼ ì•„ì¹¨ 9ì‹œ (KST) = UTC 00:00
    - cron: '0 0 * * *'
  workflow_dispatch:
    inputs:
      full_crawl:
        description: 'ì „ì²´ í¬ë¡¤ë§ (ì´ˆê¸° ìˆ˜ì§‘ìš©)'
        required: false
        type: boolean
        default: false

jobs:
  crawl:
    runs-on: ubuntu-latest
    timeout-minutes: 120

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run crawler
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
        run: |
          if [ "${{ github.event.inputs.full_crawl }}" = "true" ]; then
            node src/index.js --full
          else
            node src/index.js
          fi

      - name: Summary
        if: always()
        run: |
          echo "## ðŸ• í¬ë¡¤ë§ ì™„ë£Œ" >> $GITHUB_STEP_SUMMARY
          echo "- ì‹œê°„: $(TZ=Asia/Seoul date '+%Y-%m-%d %H:%M:%S KST')" >> $GITHUB_STEP_SUMMARY
